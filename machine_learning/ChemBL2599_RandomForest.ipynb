{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3124969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7572, 251)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_data = pd.read_csv(\"/ChemBL2599_combined_data.csv.gz\")\n",
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368937b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>pIC50_m</th>\n",
       "      <th>converted_smile_0</th>\n",
       "      <th>converted_smile_1</th>\n",
       "      <th>converted_smile_2</th>\n",
       "      <th>converted_smile_3</th>\n",
       "      <th>converted_smile_4</th>\n",
       "      <th>converted_smile_5</th>\n",
       "      <th>converted_smile_6</th>\n",
       "      <th>...</th>\n",
       "      <th>converted_smile_190</th>\n",
       "      <th>converted_smile_191</th>\n",
       "      <th>converted_smile_192</th>\n",
       "      <th>converted_smile_193</th>\n",
       "      <th>converted_smile_194</th>\n",
       "      <th>converted_smile_195</th>\n",
       "      <th>converted_smile_196</th>\n",
       "      <th>converted_smile_197</th>\n",
       "      <th>converted_smile_198</th>\n",
       "      <th>converted_smile_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>369.47</td>\n",
       "      <td>2.52</td>\n",
       "      <td>6.499997</td>\n",
       "      <td>1.854377</td>\n",
       "      <td>808.395217</td>\n",
       "      <td>19.388541</td>\n",
       "      <td>15.774469</td>\n",
       "      <td>15.774469</td>\n",
       "      <td>12.935561</td>\n",
       "      <td>9.373808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>355.45</td>\n",
       "      <td>2.01</td>\n",
       "      <td>7.500038</td>\n",
       "      <td>1.858084</td>\n",
       "      <td>808.121772</td>\n",
       "      <td>18.681434</td>\n",
       "      <td>15.119768</td>\n",
       "      <td>15.119768</td>\n",
       "      <td>12.435561</td>\n",
       "      <td>8.847099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.644743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>375.86</td>\n",
       "      <td>2.36</td>\n",
       "      <td>6.799998</td>\n",
       "      <td>1.858084</td>\n",
       "      <td>813.693554</td>\n",
       "      <td>18.681434</td>\n",
       "      <td>14.497733</td>\n",
       "      <td>15.253662</td>\n",
       "      <td>12.435561</td>\n",
       "      <td>8.536081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367.46</td>\n",
       "      <td>1.88</td>\n",
       "      <td>6.599998</td>\n",
       "      <td>1.582716</td>\n",
       "      <td>853.946965</td>\n",
       "      <td>18.802754</td>\n",
       "      <td>15.241088</td>\n",
       "      <td>15.241088</td>\n",
       "      <td>13.097357</td>\n",
       "      <td>9.554206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359.39</td>\n",
       "      <td>3.25</td>\n",
       "      <td>6.657577</td>\n",
       "      <td>1.610247</td>\n",
       "      <td>1135.828414</td>\n",
       "      <td>18.802754</td>\n",
       "      <td>14.523392</td>\n",
       "      <td>14.523392</td>\n",
       "      <td>13.097357</td>\n",
       "      <td>8.296359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Molecular Weight  AlogP   pIC50_m  converted_smile_0  converted_smile_1  \\\n",
       "0            369.47   2.52  6.499997           1.854377         808.395217   \n",
       "1            355.45   2.01  7.500038           1.858084         808.121772   \n",
       "2            375.86   2.36  6.799998           1.858084         813.693554   \n",
       "3            367.46   1.88  6.599998           1.582716         853.946965   \n",
       "4            359.39   3.25  6.657577           1.610247        1135.828414   \n",
       "\n",
       "   converted_smile_2  converted_smile_3  converted_smile_4  converted_smile_5  \\\n",
       "0          19.388541          15.774469          15.774469          12.935561   \n",
       "1          18.681434          15.119768          15.119768          12.435561   \n",
       "2          18.681434          14.497733          15.253662          12.435561   \n",
       "3          18.802754          15.241088          15.241088          13.097357   \n",
       "4          18.802754          14.523392          14.523392          13.097357   \n",
       "\n",
       "   converted_smile_6  ...  converted_smile_190  converted_smile_191  \\\n",
       "0           9.373808  ...                  0.0                  0.0   \n",
       "1           8.847099  ...                  0.0                  0.0   \n",
       "2           8.536081  ...                  0.0                  0.0   \n",
       "3           9.554206  ...                  0.0                  0.0   \n",
       "4           8.296359  ...                  0.0                  0.0   \n",
       "\n",
       "   converted_smile_192  converted_smile_193  converted_smile_194  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   converted_smile_195  converted_smile_196  converted_smile_197  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   converted_smile_198  converted_smile_199  \n",
       "0                  0.0             0.614840  \n",
       "1                  0.0             0.644743  \n",
       "2                  0.0             0.630094  \n",
       "3                  0.0             0.634156  \n",
       "4                  0.0             0.433853  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non numerical unused attributes\n",
    "machine_learning_df = combined_data.drop(columns=[\"Molecule ChEMBL ID\", \"Molecule Name\", \"Molecule Max Phase\", \"#RO5 Violations\", \n",
    "                                                  \"Compound Key\", \"Smiles\", \"Standard Type\", \"Standard Relation\", \"Standard Value\",\t\"Standard Units\", \n",
    "                                                  \"pChEMBL Value\", \"Data Validity Comment\",\t\"Comment\", \"Uo Units\", \"Ligand Efficiency BEI\",\t\"Ligand Efficiency LE\",\n",
    "                                                    \"Ligand Efficiency LLE\", \"Ligand Efficiency SEI\", \"Potential Duplicate\", \"Assay ChEMBL ID\", \"Assay Description\",\n",
    "                                                    \"Assay Type\", \"BAO Format ID\", \"BAO Label\", \"Assay Organism\", \"Assay Tissue ChEMBL ID\", \"Assay Tissue Name\",\t\n",
    "                                                    \"Assay Cell Type\", \"Assay Subcellular Fraction\", \"Assay Parameters\", \"Assay Variant Accession\", \n",
    "                                                    \"Assay Variant Mutation\", \"Target ChEMBL ID\", \"Target Name\", \"Target Organism\", \"Target Type\", \"Document ChEMBL ID\",\n",
    "                                                    \"Source ID\", \"Source Description\", \"Document Journal\", \"Document Year\", \"Cell ChEMBL ID\", \"Properties\", \"Action Type\",\n",
    "                                                    \"Standard Text Value\", \"Value\", \"IC50_m\", \"Converted Smiles\"])\n",
    "machine_learning_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbce8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Iterable, Union\n",
    "from sklearn.utils.validation import check_array, column_or_1d\n",
    "from inspect import isclass\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "def check_is_fitted(applicability_domain,\n",
    "                    attributes: Union[str, List[str], Tuple[str]],\n",
    "                    msg: str = None,\n",
    "                    all_or_any=all):\n",
    "\n",
    "    if isclass(applicability_domain):\n",
    "        raise TypeError(\"{} is a class, not an instance.\".format(applicability_domain))\n",
    "    if msg is None:\n",
    "        msg = (\n",
    "            \"This %(name)s instance is not fitted yet. Call 'fit' with \"\n",
    "            \"appropriate arguments before using this applicability domain.\"\n",
    "        )\n",
    "    if not hasattr(applicability_domain, \"fit\"):\n",
    "        raise TypeError(\"%s is not an estimator instance.\" % (applicability_domain))\n",
    "    if not isinstance(attributes, (list, tuple)):\n",
    "        attributes = [attributes]\n",
    "    is_fitted = all_or_any([hasattr(applicability_domain, attr) for attr in attributes])\n",
    "    if not is_fitted:\n",
    "        raise NotFittedError(msg % {\"name\": type(applicability_domain).__name__})\n",
    "\n",
    "class ApplicabilityDomain(ABC):\n",
    "    def __init__(self):\n",
    "        self.fitted_ = False\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = check_array(X)\n",
    "        self.num_points, self.num_dims = X.shape\n",
    "        self._fit(X)\n",
    "        self.fitted_ = True\n",
    "\n",
    "    @abstractmethod\n",
    "    def _fit(self, X):\n",
    "        pass\n",
    "\n",
    "    def contains(self, sample) -> Union[bool, Iterable[bool]]:\n",
    "        check_is_fitted(self, 'fitted_')\n",
    "        try:\n",
    "            sample = column_or_1d(sample)\n",
    "        except ValueError:\n",
    "            sample = check_array(sample, accept_large_sparse=False)\n",
    "        if sample.ndim == 1 and sample.shape[0] != self.num_dims:\n",
    "            raise ValueError('sample must have the same number of features as the applicability domain; '\n",
    "                             f'{sample.shape[0]} and {self.num_dims} respectively')\n",
    "        elif sample.ndim == 2 and sample.shape[1] != self.num_dims:\n",
    "            raise ValueError('sample must have the same number of features as the applicability domain; '\n",
    "                             f'{sample.shape[1]} and {self.num_dims} respectively')\n",
    "        return self._contains(sample)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _contains(self, sample):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262667f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from typing import Union, Tuple, Optional\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy.random import RandomState\n",
    "from scipy.spatial.distance import cdist, _METRICS as dist_fns\n",
    "from scipy.stats import f as Fdistrib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors\n",
    "from sklearn.neighbors._kde import KernelDensity\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, MaxAbsScaler, StandardScaler\n",
    "from sklearn.utils.extmath import stable_cumsum\n",
    "\n",
    "class TopKatApplicabilityDomain(ApplicabilityDomain):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _fit(self, X):\n",
    "        self.X_min_, self.X_max_ = X.min(axis=0), X.max(axis=0)\n",
    "        S = (2 * X - self.X_max_ - self.X_min_) / np.where((self.X_max_ - self.X_min_) != 0,\n",
    "                                                           (self.X_max_ - self.X_min_),1)\n",
    "        S = np.c_[np.ones(S.shape[0]), S]\n",
    "        self.eigen_val, self.eigen_vec = np.linalg.eig(S.T.dot(S))\n",
    "        self.eigen_val, self.eigen_vec = np.real(self.eigen_val), np.real(self.eigen_vec)\n",
    "        OPS = S.dot(self.eigen_vec)\n",
    "        self.OPS_min_ = OPS.min(axis=0)\n",
    "        self.OPS_max_ = OPS.max(axis=0)\n",
    "\n",
    "    def _contains(self, sample):\n",
    "        Ssample = (2 * sample - self.X_max_ - self.X_min_) / np.where((self.X_max_ - self.X_min_) != 0,\n",
    "                                                                      (self.X_max_ - self.X_min_),1)\n",
    "        if sample.ndim == 1:\n",
    "            Ssample = np.c_[1, Ssample.reshape((1, -1))]\n",
    "        else:\n",
    "            Ssample = np.c_[np.ones((sample.shape[0], 1)), Ssample]\n",
    "        OPS_sample = Ssample.dot(self.eigen_vec)\n",
    "        denom = np.divide(np.ones_like(self.eigen_val, dtype=float),\n",
    "                          self.eigen_val,\n",
    "                          out=np.zeros_like(self.eigen_val),\n",
    "                          where=self.eigen_val!=0)\n",
    "        dOPS = (OPS_sample * OPS_sample).dot(denom)\n",
    "        if sample.ndim == 1 and isinstance(dOPS, np.ndarray):\n",
    "            dOPS = dOPS.item()\n",
    "        return dOPS < (5 * (self.num_dims)) / (2 * self.num_points)\n",
    "\n",
    "\n",
    "class LeverageApplicabilityDomain(ApplicabilityDomain):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def _fit(self, X):\n",
    "        X = self.scaler.fit_transform(X)\n",
    "        self.var_covar = np.linalg.inv(X.T.dot(X))\n",
    "        self.threshold = 3 * (self.num_dims + 1) / self.num_points\n",
    "\n",
    "    def _contains(self, sample):\n",
    "        if sample.ndim == 1:\n",
    "            sample = self.scaler.transform(sample.reshape(1, -1))\n",
    "            h = sample.dot(self.var_covar).dot(sample.T)\n",
    "        else:\n",
    "            sample = self.scaler.transform(sample)\n",
    "            h = np.diag(sample.dot(self.var_covar).dot(sample.T))\n",
    "        return h < self.threshold\n",
    "\n",
    "class KNNApplicabilityDomain(ApplicabilityDomain):\n",
    "    def __init__(self, k: int = 5,\n",
    "                 alpha: float = 0.95,\n",
    "                 hard_threshold: float = None,\n",
    "                 scaling: Optional[str] = 'robust',\n",
    "                 dist: str = 'euclidean',\n",
    "                 scaler_kwargs=None,\n",
    "                 njobs: int=1):\n",
    "        super().__init__()\n",
    "        if scaler_kwargs is None:\n",
    "            scaler_kwargs = {}\n",
    "        if alpha > 1 or alpha < 0:\n",
    "            raise ValueError('alpha must lie between 0 and 1')\n",
    "        scaling_methods = ('robust', 'minmax', 'maxabs', 'standard', None)\n",
    "        if scaling not in scaling_methods:\n",
    "            raise ValueError(f'scaling method must be one of {scaling_methods}')\n",
    "        if scaling == 'robust':\n",
    "            self.scaler = RobustScaler(**scaler_kwargs)\n",
    "        elif scaling == 'minmax':\n",
    "            self.scaler = MinMaxScaler(**scaler_kwargs)\n",
    "        elif scaling == 'maxabs':\n",
    "            self.scaler = MaxAbsScaler(**scaler_kwargs)\n",
    "        elif scaling == 'standard':\n",
    "            self.scaler = StandardScaler(**scaler_kwargs)\n",
    "        elif scaling is None:\n",
    "            self.scaler = None\n",
    "        else:\n",
    "            raise NotImplementedError('scaling method not implemented')\n",
    "        if dist not in dist_fns.keys():\n",
    "            raise NotImplementedError('distance type is not available')\n",
    "        else:\n",
    "            self.dist = dist\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.hard_threshold = hard_threshold\n",
    "        self.nn = NearestNeighbors(n_neighbors=k, metric=dist, n_jobs=njobs)\n",
    "\n",
    "    def _fit(self, X):\n",
    "        self.X_norm = self.scaler.fit_transform(X) if self.scaler is not None else X\n",
    "        self.nn.fit(self.X_norm)\n",
    "        self.kNN_dist = self.nn.kneighbors(self.X_norm, return_distance=True, n_neighbors=self.k+1)[0][:, 1:].mean(axis=1)\n",
    "        kNN_train_distance_sorted_ = np.trim_zeros(np.sort(self.kNN_dist))\n",
    "        if self.hard_threshold:\n",
    "            self.threshold_ = self.hard_threshold\n",
    "        else:\n",
    "            self.threshold_ = kNN_train_distance_sorted_[floor(kNN_train_distance_sorted_.shape[0] * self.alpha) - 1]\n",
    "        return self\n",
    "\n",
    "    def _contains(self, sample):\n",
    "        if self.scaler is not None:\n",
    "            if sample.ndim == 1:\n",
    "                sample = self.scaler.transform(sample.reshape((1, len(sample))))\n",
    "            else:\n",
    "                sample = self.scaler.transform(sample)\n",
    "        kNN_sample_dist = self.nn.kneighbors(sample, return_distance=True)[0].mean(axis=1)\n",
    "        norm_dist = kNN_sample_dist / self.threshold_\n",
    "        if self.hard_threshold:\n",
    "            return norm_dist < 1\n",
    "        return norm_dist <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a2ab33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 202\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 0.6, 'max_depth': None, 'bootstrap': True}\n",
      "Training R2: 0.8913321283602652, Test R2: 0.7065308558535759\n",
      "Training MSE: 0.14556093844107282, Test MSE: 0.38190521338608413\n",
      "Training MAE: 0.24938482548944252, Test MAE: 0.4205877601271368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "X = machine_learning_df.drop(columns=[\"pIC50_m\"])\n",
    "y = machine_learning_df[\"pIC50_m\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "base_rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=base_rf,\n",
    "    step=10,\n",
    "    min_features_to_select=20,\n",
    "    cv=KFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "X_train_rfe = rfecv.transform(X_train)\n",
    "X_test_rfe = rfecv.transform(X_test)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [200, 300, 400],\n",
    "    \"max_depth\": [None, 10, 15],\n",
    "    \"min_samples_split\": [5, 10, 15],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"max_features\": [\"sqrt\", 0.6, 0.7],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring=\"r2\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_rfe, y_train)\n",
    "\n",
    "best_rf = random_search.best_estimator_\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "\n",
    "y_pred_train = best_rf.predict(X_train_rfe)\n",
    "y_pred_test = best_rf.predict(X_test_rfe)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21537a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.8886791572793092, Test R2: 0.6937782699111775\n",
      "Training MSE: 0.14150102277951823, Test MSE: 0.3769613519391465\n",
      "Training MAE: 0.24540610670821436, Test MAE: 0.41639559667792\n"
     ]
    }
   ],
   "source": [
    "# The following applicability domains use variables produced from the Random Forest code above.\n",
    "\n",
    "ad = TopKatApplicabilityDomain()\n",
    "ad.fit(X_train_rfe)\n",
    "\n",
    "inside_ad_train = ad.contains(X_train_rfe)\n",
    "inside_ad_test = ad.contains(X_test_rfe)\n",
    "\n",
    "y_train_inside = y_train[inside_ad_train]\n",
    "y_pred_train_inside = y_pred_train[inside_ad_train]\n",
    "\n",
    "y_test_inside = y_test[inside_ad_test]\n",
    "y_pred_test_inside = y_pred_test[inside_ad_test]\n",
    "\n",
    "r2_train = r2_score(y_train_inside, y_pred_train_inside)\n",
    "r2_test = r2_score(y_test_inside, y_pred_test_inside)\n",
    "mse_train = mean_squared_error(y_train_inside, y_pred_train_inside)\n",
    "mse_test = mean_squared_error(y_test_inside, y_pred_test_inside)\n",
    "mae_train = mean_absolute_error(y_train_inside, y_pred_train_inside)\n",
    "mae_test = mean_absolute_error(y_test_inside, y_pred_test_inside)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5984b44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.8912425702876093, Test R2: 0.7080209269562807\n",
      "Training MSE: 0.14858592901048454, Test MSE: 0.39223213957288783\n",
      "Training MAE: 0.25218144710096424, Test MAE: 0.4274065223053353\n"
     ]
    }
   ],
   "source": [
    "# The following applicability domains use variables produced from the Random Forest code above.\n",
    "\n",
    "ad = KNNApplicabilityDomain()\n",
    "ad.fit(X_train_rfe)\n",
    "\n",
    "inside_ad_train = ad.contains(X_train_rfe)\n",
    "inside_ad_test = ad.contains(X_test_rfe)\n",
    "\n",
    "y_train_inside = y_train[inside_ad_train]\n",
    "y_pred_train_inside = y_pred_train[inside_ad_train]\n",
    "\n",
    "y_test_inside = y_test[inside_ad_test]\n",
    "y_pred_test_inside = y_pred_test[inside_ad_test]\n",
    "\n",
    "r2_train = r2_score(y_train_inside, y_pred_train_inside)\n",
    "r2_test = r2_score(y_test_inside, y_pred_test_inside)\n",
    "mse_train = mean_squared_error(y_train_inside, y_pred_train_inside)\n",
    "mse_test = mean_squared_error(y_test_inside, y_pred_test_inside)\n",
    "mae_train = mean_absolute_error(y_train_inside, y_pred_train_inside)\n",
    "mae_test = mean_absolute_error(y_test_inside, y_pred_test_inside)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3701745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 74 outliers from training set.\n",
      "Training R2: 0.8778325608824171, Test R2: 0.6441102280123767\n",
      "Training MSE: 0.142587117545208, Test MSE: 0.463136115069882\n",
      "Training MAE: 0.2485212298809906, Test MAE: 0.44564335475910405\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "selected_features = X.columns[rfecv.support_]\n",
    "\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "z_scores = np.abs(zscore(y_train))\n",
    "mask = (z_scores < 3)\n",
    "X_train_clean = X_train[mask]\n",
    "y_train_clean = y_train[mask]\n",
    "\n",
    "print(f\"Removed {len(X_train) - len(X_train_clean)} outliers from training set.\")\n",
    "\n",
    "final_rf = RandomForestRegressor(n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features=0.6, max_depth=None, bootstrap=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "final_rf.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "y_pred_train = final_rf.predict(X_train_clean)\n",
    "y_pred_test = final_rf.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train_clean, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train_clean, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "mae_train = mean_absolute_error(y_train_clean, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ce35e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.8767775242659804, Test R2: 0.6673665648018905\n",
      "Training MSE: 0.13845495121040607, Test MSE: 0.38162543959826384\n",
      "Training MAE: 0.24443978631089297, Test MAE: 0.4189405124278786\n"
     ]
    }
   ],
   "source": [
    "# The following applicability domains use variables produced from the Random Forest code above.\n",
    "\n",
    "ad = TopKatApplicabilityDomain()\n",
    "ad.fit(X_train_clean)\n",
    "\n",
    "inside_ad_train = ad.contains(X_train_clean)\n",
    "inside_ad_test = ad.contains(X_test)\n",
    "\n",
    "y_train_inside = y_train_clean[inside_ad_train]\n",
    "y_pred_train_inside = y_pred_train[inside_ad_train]\n",
    "\n",
    "y_test_inside = y_test[inside_ad_test]\n",
    "y_pred_test_inside = y_pred_test[inside_ad_test]\n",
    "\n",
    "r2_train = r2_score(y_train_inside, y_pred_train_inside)\n",
    "r2_test = r2_score(y_test_inside, y_pred_test_inside)\n",
    "mse_train = mean_squared_error(y_train_inside, y_pred_train_inside)\n",
    "mse_test = mean_squared_error(y_test_inside, y_pred_test_inside)\n",
    "mae_train = mean_absolute_error(y_train_inside, y_pred_train_inside)\n",
    "mae_test = mean_absolute_error(y_test_inside, y_pred_test_inside)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bfe34e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.8773465353709234, Test R2: 0.6442096970151443\n",
      "Training MSE: 0.14571388509549324, Test MSE: 0.4779534037295207\n",
      "Training MAE: 0.2516757570766046, Test MAE: 0.45428817647449576\n"
     ]
    }
   ],
   "source": [
    "# The following applicability domains use variables produced from the Random Forest code above.\n",
    "\n",
    "ad = KNNApplicabilityDomain()\n",
    "ad.fit(X_train_clean)\n",
    "\n",
    "inside_ad_train = ad.contains(X_train_clean)\n",
    "inside_ad_test = ad.contains(X_test)\n",
    "\n",
    "y_train_inside = y_train_clean[inside_ad_train]\n",
    "y_pred_train_inside = y_pred_train[inside_ad_train]\n",
    "\n",
    "y_test_inside = y_test[inside_ad_test]\n",
    "y_pred_test_inside = y_pred_test[inside_ad_test]\n",
    "\n",
    "r2_train = r2_score(y_train_inside, y_pred_train_inside)\n",
    "r2_test = r2_score(y_test_inside, y_pred_test_inside)\n",
    "mse_train = mean_squared_error(y_train_inside, y_pred_train_inside)\n",
    "mse_test = mean_squared_error(y_test_inside, y_pred_test_inside)\n",
    "mae_train = mean_absolute_error(y_train_inside, y_pred_train_inside)\n",
    "mae_test = mean_absolute_error(y_test_inside, y_pred_test_inside)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91a2636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 93 outliers from training set using IQR.\n",
      "Training R2: 0.8788297516353866, Test R2: 0.6295325894404422\n",
      "Training MSE: 0.1377237829368992, Test MSE: 0.482106682437953\n",
      "Training MAE: 0.24684874366445994, Test MAE: 0.4499569013762883\n"
     ]
    }
   ],
   "source": [
    "selected_features = X.columns[rfecv.support_]\n",
    "\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "Q1 = y_train.quantile(0.25)\n",
    "Q3 = y_train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = (y_train >= (Q1 - 1.5 * IQR)) & (y_train <= (Q3 + 1.5 * IQR))\n",
    "X_train_clean = X_train[mask]\n",
    "y_train_clean = y_train[mask]\n",
    "\n",
    "print(f\"Removed {len(X_train) - len(X_train_clean)} outliers from training set using IQR.\")\n",
    "\n",
    "final_rf = RandomForestRegressor(n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features=0.6, max_depth=None, bootstrap=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "final_rf.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "y_pred_train = final_rf.predict(X_train_clean)\n",
    "y_pred_test = final_rf.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train_clean, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train_clean, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "mae_train = mean_absolute_error(y_train_clean, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c7b521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.8783735046328097, Test R2: 0.6610809508694999\n",
      "Training MSE: 0.13370224371954362, Test MSE: 0.38936250499707353\n",
      "Training MAE: 0.2429276653807333, Test MAE: 0.42126439932481247\n"
     ]
    }
   ],
   "source": [
    "# The following applicability domains use variables produced from the Random Forest code above.\n",
    "\n",
    "ad = TopKatApplicabilityDomain()\n",
    "ad.fit(X_train_clean)\n",
    "\n",
    "inside_ad_train = ad.contains(X_train_clean)\n",
    "inside_ad_test = ad.contains(X_test)\n",
    "\n",
    "y_train_inside = y_train_clean[inside_ad_train]\n",
    "y_pred_train_inside = y_pred_train[inside_ad_train]\n",
    "\n",
    "y_test_inside = y_test[inside_ad_test]\n",
    "y_pred_test_inside = y_pred_test[inside_ad_test]\n",
    "\n",
    "r2_train = r2_score(y_train_inside, y_pred_train_inside)\n",
    "r2_test = r2_score(y_test_inside, y_pred_test_inside)\n",
    "mse_train = mean_squared_error(y_train_inside, y_pred_train_inside)\n",
    "mse_test = mean_squared_error(y_test_inside, y_pred_test_inside)\n",
    "mae_train = mean_absolute_error(y_train_inside, y_pred_train_inside)\n",
    "mae_test = mean_absolute_error(y_test_inside, y_pred_test_inside)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aedfbcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.8784330931901223, Test R2: 0.6293987483826379\n",
      "Training MSE: 0.1405745140706707, Test MSE: 0.49784979565471277\n",
      "Training MAE: 0.2498505991910728, Test MAE: 0.45844278504563746\n"
     ]
    }
   ],
   "source": [
    "# The following applicability domains use variables produced from the Random Forest code above.\n",
    "\n",
    "ad = KNNApplicabilityDomain()\n",
    "ad.fit(X_train_clean)\n",
    "\n",
    "inside_ad_train = ad.contains(X_train_clean)\n",
    "inside_ad_test = ad.contains(X_test)\n",
    "\n",
    "y_train_inside = y_train_clean[inside_ad_train]\n",
    "y_pred_train_inside = y_pred_train[inside_ad_train]\n",
    "\n",
    "y_test_inside = y_test[inside_ad_test]\n",
    "y_pred_test_inside = y_pred_test[inside_ad_test]\n",
    "\n",
    "r2_train = r2_score(y_train_inside, y_pred_train_inside)\n",
    "r2_test = r2_score(y_test_inside, y_pred_test_inside)\n",
    "mse_train = mean_squared_error(y_train_inside, y_pred_train_inside)\n",
    "mse_test = mean_squared_error(y_test_inside, y_pred_test_inside)\n",
    "mae_train = mean_absolute_error(y_train_inside, y_pred_train_inside)\n",
    "mae_test = mean_absolute_error(y_test_inside, y_pred_test_inside)\n",
    "\n",
    "print(f\"Training R2: {r2_train}, Test R2: {r2_test}\")\n",
    "print(f\"Training MSE: {mse_train}, Test MSE: {mse_test}\")\n",
    "print(f\"Training MAE: {mae_train}, Test MAE: {mae_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
